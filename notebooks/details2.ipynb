{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "I modify the code to be able to evaluate validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_and_model():\n",
    "    # set random seed\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # create a dataset with numpy arrays\n",
    "    x = np.random.random((100, 10))\n",
    "    y = np.random.randint(0, 2, (100, 1))\n",
    "    x = tf.data.Dataset.from_tensor_slices(x)\n",
    "    y = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "    # shuffling and batching the dataset\n",
    "    train_data = tf.data.Dataset.zip((x, y)).shuffle(100).batch(10)\n",
    "\n",
    "    # create a dataset with numpy arrays\n",
    "    x = np.random.random((100, 10))\n",
    "    y = np.random.randint(0, 2, (100, 1))\n",
    "    x = tf.data.Dataset.from_tensor_slices(x)\n",
    "    y = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "    # shuffling and batching the dataset\n",
    "    validation_data = tf.data.Dataset.zip((x, y)).batch(10)\n",
    "\n",
    "    # create a model to train on the dataset\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(10)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=\"accuracy\")\n",
    "    return train_data, validation_data, model\n",
    "\n",
    "\n",
    "def train(data, model, epochs, validation_data=None, initial_epoch=0, initial_step=0, epoch_period=0, step_period=0, ckpt_dir=\"checkpoint\"):\n",
    "    cm = CheckpointManager(ckpt_dir)\n",
    "\n",
    "    iterator = iter(data)\n",
    "\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        cm.restore_iterator(iterator, initial_epoch, initial_step)\n",
    "        cm.restore_model(model, initial_epoch, initial_step)\n",
    "\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        cm.restore_history(callbacks, initial_epoch, initial_step)\n",
    "\n",
    "    logs = None\n",
    "    for epoch in range(initial_epoch, epochs):\n",
    "\n",
    "        if initial_step == 0:\n",
    "            iterator = iter(data)\n",
    "            model.reset_metrics()\n",
    "        \n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        for step in range(initial_step, steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            logs = train_fn(iterator)\n",
    "\n",
    "            if initial_step != 0 and step == initial_step:\n",
    "                logs = cm.restore_metrics(model, initial_epoch, initial_step)\n",
    "\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "            \n",
    "            if step_period != 0 and (step + 1) % step_period == 0:\n",
    "                cm.save_iterator(iterator, epoch, step + 1)\n",
    "                cm.save_model(model, epoch, step + 1)\n",
    "                cm.save_metrics(model, epoch, step + 1)\n",
    "                cm.save_history(callbacks, epoch, step + 1)\n",
    "\n",
    "        if initial_step != 0:\n",
    "            initial_step = 0\n",
    "\n",
    "        # validation step\n",
    "        if validation_data:\n",
    "            val_logs = model.evaluate(validation_data, callbacks=callbacks, return_dict=True)\n",
    "            val_logs = {\"val_\" + name: val for name, val in val_logs.items()}\n",
    "            logs.update(val_logs)\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "        if epoch_period != 0 and (epoch + 1) % epoch_period == 0:\n",
    "            cm.save_iterator(iterator, epoch + 1, 0)\n",
    "            cm.save_model(model, epoch + 1, 0)\n",
    "            cm.save_metrics(model, epoch + 1, 0)\n",
    "            cm.save_history(callbacks, epoch + 1, 0)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can reproduce the result of `model.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2.1481 - accuracy: 0.5100 - val_loss: 1.6133 - val_accuracy: 0.6400\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9838 - accuracy: 0.4900 - val_loss: 1.2293 - val_accuracy: 0.6400\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8324 - accuracy: 0.4900 - val_loss: 1.1985 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8124 - accuracy: 0.4900 - val_loss: 1.1877 - val_accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8042 - accuracy: 0.5000 - val_loss: 1.1842 - val_accuracy: 0.6500\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5], 'val_loss': [1.6133465766906738, 1.229250192642212, 1.1984832286834717, 1.1877398490905762, 1.1842304468154907], 'val_accuracy': [0.6399999856948853, 0.6399999856948853, 0.6499999761581421, 0.6499999761581421, 0.6499999761581421]}\n",
      "\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 2.1481 - accuracy: 0.5100 - val_loss: 1.6133 - val_accuracy: 0.6400\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9838 - accuracy: 0.4900 - val_loss: 1.2293 - val_accuracy: 0.6400\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8324 - accuracy: 0.4900 - val_loss: 1.1985 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8124 - accuracy: 0.4900 - val_loss: 1.1877 - val_accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8042 - accuracy: 0.5000 - val_loss: 1.1842 - val_accuracy: 0.6500\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5], 'val_loss': [1.6133465766906738, 1.229250192642212, 1.1984832286834717, 1.1877398490905762, 1.1842304468154907], 'val_accuracy': [0.6399999856948853, 0.6399999856948853, 0.6499999761581421, 0.6499999761581421, 0.6499999761581421]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_data, validation_data, model = create_data_and_model()\n",
    "history = model.fit(train_data, epochs=epochs, validation_data=validation_data)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "epochs = 5\n",
    "train_data, validation_data, model = create_data_and_model()\n",
    "history = train(train_data, model, epochs, validation_data=validation_data)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modification doesn't effect on saving the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 2.1481 - accuracy: 0.5100 - val_loss: 1.6133 - val_accuracy: 0.6400\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.9838 - accuracy: 0.4900 - val_loss: 1.2293 - val_accuracy: 0.6400\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.8324 - accuracy: 0.4900 - val_loss: 1.1985 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.8124 - accuracy: 0.4900 - val_loss: 1.1877 - val_accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.8042 - accuracy: 0.5000 - val_loss: 1.1842 - val_accuracy: 0.6500\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5], 'val_loss': [1.6133465766906738, 1.229250192642212, 1.1984832286834717, 1.1877398490905762, 1.1842304468154907], 'val_accuracy': [0.6399999856948853, 0.6399999856948853, 0.6499999761581421, 0.6499999761581421, 0.6499999761581421]}\n",
      "\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.8324 - accuracy: 0.4900 - val_loss: 1.1985 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8124 - accuracy: 0.4900 - val_loss: 1.1877 - val_accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8042 - accuracy: 0.5000 - val_loss: 1.1842 - val_accuracy: 0.6500\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5], 'val_loss': [1.6133465766906738, 1.229250192642212, 1.1984832286834717, 1.1877398490905762, 1.1842304468154907], 'val_accuracy': [0.6399999856948853, 0.6399999856948853, 0.6499999761581421, 0.6499999761581421, 0.6499999761581421]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "step_period = 3\n",
    "epoch_period = 1\n",
    "train_data, validation_data, model = create_data_and_model()\n",
    "history = train(train_data, model, epochs, validation_data=validation_data, step_period=step_period, epoch_period=epoch_period)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "epochs = 5\n",
    "initial_step = 3\n",
    "initial_epoch = 2\n",
    "train_data, validation_data, model = create_data_and_model()\n",
    "history = train(train_data, model, epochs, validation_data=validation_data, initial_step=initial_step, initial_epoch=initial_epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77380b671049c866ddb2cbea35f435cceddb611c25b08154848521dfc0769a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
