{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "First, I create a dataset and a model, and train the model with `model.fit()`. \n",
    "\n",
    "One of the requirements of our code is that it can reproduce the following result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 0s 664us/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 554us/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 650us/step - loss: 1.8324 - accuracy: 0.4900\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316]}\n"
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# create a dataset with numpy arrays\n",
    "x = np.random.random((100, 10))\n",
    "y = np.random.randint(0, 2, (100, 1))\n",
    "x = tf.data.Dataset.from_tensor_slices(x)\n",
    "y = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "# shuffling and batching the dataset\n",
    "dataset = tf.data.Dataset.zip((x, y)).shuffle(100).batch(10)\n",
    "\n",
    "# create a model to train on the dataset\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(10)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "# training\n",
    "epochs = 3\n",
    "history = model.fit(dataset, epochs=epochs)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the toy dataset.\n",
    "The input is a 10-dimensional random vector and the output is a random label 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: shape=(10, 10)\n",
      "[[0.57019677 0.43860151 0.98837384 0.10204481 0.20887676 0.16130952\n",
      "  0.65310833 0.2532916  0.46631077 0.24442559]\n",
      " [0.06271295 0.42403225 0.25868407 0.84903831 0.03330463 0.95898272\n",
      "  0.35536885 0.35670689 0.0163285  0.18523233]\n",
      " [0.1390727  0.42690436 0.84285489 0.81803331 0.10241376 0.15638335\n",
      "  0.30419869 0.07535907 0.424663   0.10761771]\n",
      " [0.69742877 0.45354268 0.7220556  0.86638233 0.97552151 0.85580334\n",
      "  0.01171408 0.35997806 0.72999056 0.17162968]\n",
      " [0.18115096 0.78854551 0.05684808 0.69699724 0.7786954  0.77740756\n",
      "  0.25942256 0.37381314 0.58759964 0.2728219 ]\n",
      " [0.30040368 0.54950057 0.93081872 0.52076144 0.26720703 0.87739879\n",
      "  0.37191875 0.00138335 0.24768502 0.31823351]\n",
      " [0.8965466  0.36756187 0.43586493 0.89192336 0.80619399 0.70388858\n",
      "  0.10022689 0.91948261 0.7142413  0.99884701]\n",
      " [0.04680635 0.97073144 0.00386035 0.17857997 0.61286675 0.0813696\n",
      "  0.8818965  0.71962016 0.96638997 0.50763555]\n",
      " [0.99033895 0.21689698 0.6630782  0.26332238 0.020651   0.75837865\n",
      "  0.32001715 0.38346389 0.58831711 0.83104846]\n",
      " [0.65731892 0.51732608 0.48496565 0.90116217 0.55464506 0.8268616\n",
      "  0.72557353 0.03855725 0.77311005 0.21687025]]\n",
      "\n",
      "Target: shape=(10, 1)\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "for xi, yi in dataset.take(1).as_numpy_iterator():\n",
    "    print(f\"Input: shape={xi.shape}\")\n",
    "    print(xi)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(f\"Target: shape={yi.shape}\")\n",
    "    print(yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I prepare a method to create a dataset and a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_and_model():\n",
    "    # set random seed\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # create a dataset with numpy arrays\n",
    "    x = np.random.random((100, 10))\n",
    "    y = np.random.randint(0, 2, (100, 1))\n",
    "    x = tf.data.Dataset.from_tensor_slices(x)\n",
    "    y = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "    # shuffling and batching the dataset\n",
    "    data = tf.data.Dataset.zip((x, y)).shuffle(100).batch(10)\n",
    "\n",
    "    # create a model to train on the dataset\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(10)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=\"accuracy\")\n",
    "    return data, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Restore a Dataset\n",
    "\n",
    "I need to save and restore the dataset because it has states such as a random state used by `shuffle()`. \n",
    "\n",
    "So I would like to customize `model.fit()`.\n",
    "One way is to implement a custom callback as described [here](https://www.tensorflow.org/guide/keras/custom_callback). \n",
    "\n",
    "However, it seems to be hard to access the dataset from a callback. \n",
    "Therefore, I first try to reproduce the behaviour of `model.fit()` as much as possible using the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(data, model, epochs):\n",
    "    # create an iterator\n",
    "    iterator = iter(data)\n",
    "\n",
    "    # create callbacks\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    # training\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    logs = None\n",
    "    for epoch in range(epochs):\n",
    "        iterator = iter(data)\n",
    "        model.reset_metrics()\n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        for step in range(steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            logs = train_fn(iterator)\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the result is the same as when training with `model.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.fit()\n",
      "Epoch 1/3\n",
      "10/10 [==============================] - 0s 665us/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 554us/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 643us/step - loss: 1.8324 - accuracy: 0.4900\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316]}\n",
      "\n",
      "custom training\n",
      "Epoch 1/3\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 698us/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 698us/step - loss: 1.8324 - accuracy: 0.4900\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# model.fit()\n",
    "print(\"model.fit()\")\n",
    "data, model = create_data_and_model()\n",
    "history = model.fit(data, epochs=epochs)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "# custom training\n",
    "print(\"custom training\")\n",
    "data, model = create_data_and_model()\n",
    "history = train1(data, model, epochs)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to get the same result is the line 3. \n",
    "```python\n",
    "iterator = iter(data)\n",
    "```\n",
    "In `model.fit()`, this is called at the beginning of the training to convert a dataset to an iterator, and is also called at the beginning of each epoch to get data used in the epoch. \n",
    "\n",
    "This means that the very first cycle of the dataset is not used anywhere. So let's see what happens without the line 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(data, model, epochs):\n",
    "    # create callbacks\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    # training\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    logs = None\n",
    "    for epoch in range(epochs):\n",
    "        iterator = iter(data)\n",
    "        model.reset_metrics()\n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        for step in range(steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            logs = train_fn(iterator)\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.fit()\n",
      "Epoch 1/3\n",
      "10/10 [==============================] - 0s 775us/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 776us/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 665us/step - loss: 1.8324 - accuracy: 0.4900\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316]}\n",
      "\n",
      "custom training\n",
      "Epoch 1/3\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.2871 - accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 599us/step - loss: 2.0245 - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 598us/step - loss: 1.8891 - accuracy: 0.4900\n",
      "{'loss': [2.287079334259033, 2.024529457092285, 1.88909912109375], 'accuracy': [0.5, 0.5, 0.49000000953674316]}\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# model.fit()\n",
    "print(\"model.fit()\")\n",
    "data, model = create_data_and_model()\n",
    "history = model.fit(data, epochs=epochs)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "# custom training\n",
    "print(\"custom training\")\n",
    "data, model = create_data_and_model()\n",
    "history = train2(data, model, epochs)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I modify `train1()` so that I can save and restore the dataset. \n",
    "The way to create checkpoints of a dataset during training is described [here](https://www.tensorflow.org/guide/checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to ckechpoint files\n",
    "ckpt_dir = \"checkpoint\"\n",
    "ckpt_path = os.path.join(ckpt_dir, \"ckpt_{epoch:04d}_{step:04d}\", \"{name}\")\n",
    "\n",
    "\n",
    "# save a dataset\n",
    "def save_iterator(iterator, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"iterator\")\n",
    "    ckpt = tf.train.Checkpoint(iterator)\n",
    "    ckpt.write(path)\n",
    "    return\n",
    "\n",
    "\n",
    "# restore a dataset\n",
    "def restore_iterator(iterator, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"iterator\")\n",
    "    ckpt = tf.train.Checkpoint(iterator)\n",
    "    ckpt.read(path).assert_consumed()\n",
    "    return\n",
    "\n",
    "\n",
    "def train3(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period):\n",
    "    iterator = iter(data)\n",
    "\n",
    "    # restore the dataset\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        restore_iterator(iterator, initial_epoch, initial_step)\n",
    "\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    # start at the \"initial_epoch\"th epoch\n",
    "    logs = None\n",
    "    for epoch in range(initial_epoch, epochs):\n",
    "\n",
    "        # initialize if starting an epoch from the beginning\n",
    "        if initial_step == 0:\n",
    "            iterator = iter(data)\n",
    "            model.reset_metrics()\n",
    "        \n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        # start at the \"initial_step\"th step for only the first epoch\n",
    "        for step in range(initial_step, steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            #logs = train_fn(iterator)\n",
    "\n",
    "            # only for displaying a dataset\n",
    "            x, y = next(iterator)\n",
    "            print(x.numpy()[0, :5])\n",
    "\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "\n",
    "            # save the dataset every \"step_period\" steps\n",
    "            if step_period != 0 and (step + 1) % step_period == 0:\n",
    "                save_iterator(iterator, epoch, step + 1)\n",
    "\n",
    "        # reset \"initial_step\" after the first epoch\n",
    "        if initial_step != 0:\n",
    "            initial_step = 0\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "        # save the dataset every \"epochs_period\" epochs\n",
    "        if epoch_period != 0 and (epoch + 1) % epoch_period == 0:\n",
    "            save_iterator(iterator, epoch + 1, 0)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code enables to save the dataset every `step_period` steps and/or every `epoch_period` epochs, and restart the training from the `initial_step`th step of the `initial_epoch`th epoch. \n",
    "\n",
    "Note that it doesn't perform training but only display elements of the dataset to check the behaviour. Now let's try to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the dataset every 3 steps\n",
      "[0.00270321 0.64719665 0.60039224 0.58873961 0.96277032]\n",
      " 2/10 [=====>........................] - ETA: 0s[0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]\n",
      "[0.60571196 0.11566187 0.72788816 0.63746228 0.81193856]\n",
      "[0.50106317 0.37638916 0.36491184 0.2609045  0.4959703 ]\n",
      "[0.18115096 0.78854551 0.05684808 0.69699724 0.7786954 ]\n",
      "[0.31038083 0.37303486 0.52497044 0.75059502 0.33350747]\n",
      "[0.4012595  0.92929142 0.09961493 0.94530153 0.86948853]\n",
      "[0.42370635 0.85712492 0.11731556 0.27125208 0.40379274]\n",
      "[0.351893   0.72140667 0.63758269 0.81305386 0.97622566]\n",
      "[0.44132147 0.48641045 0.44836918 0.567846   0.62116925]\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "\n",
      "restart the training from the 3rd step of the first epoch\n",
      "[0.50106317 0.37638916 0.36491184 0.2609045  0.4959703 ]\n",
      " 5/10 [==============>...............] - ETA: 0s[0.18115096 0.78854551 0.05684808 0.69699724 0.7786954 ]\n",
      "[0.31038083 0.37303486 0.52497044 0.75059502 0.33350747]\n",
      "[0.4012595  0.92929142 0.09961493 0.94530153 0.86948853]\n",
      "[0.42370635 0.85712492 0.11731556 0.27125208 0.40379274]\n",
      "[0.351893   0.72140667 0.63758269 0.81305386 0.97622566]\n",
      "[0.44132147 0.48641045 0.44836918 0.567846   0.62116925]\n",
      "10/10 [==============================] - 0s 361us/step\n"
     ]
    }
   ],
   "source": [
    "# save the dataset\n",
    "print(\"save the dataset every 3 steps\")\n",
    "epochs = 1\n",
    "initial_epoch = 0\n",
    "initial_step = 0\n",
    "epoch_period = 0\n",
    "step_period = 3\n",
    "data, model = create_data_and_model()\n",
    "history = train3(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "\n",
    "print()\n",
    "\n",
    "# restore the dataset\n",
    "print(\"restart the training from the 3rd step of the first epoch\")\n",
    "epochs = 1\n",
    "initial_epoch = 0\n",
    "initial_step = 3\n",
    "epoch_period = 0\n",
    "step_period = 0\n",
    "data, model = create_data_and_model()\n",
    "history = train3(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Restore a Model\n",
    "\n",
    "Of course, I need to save and restore the model too.\n",
    "There are mainly two ways to do that as described [here](https://www.tensorflow.org/tutorials/keras/save_and_load).\n",
    "\n",
    "One way saves the model architecture and the model weights, and the other way saves only the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and restore a model architecture and model weights\n",
    "def save_model1(model, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"model\")\n",
    "    model.save(path)\n",
    "    return\n",
    "\n",
    "def restore_model1(epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"model\")\n",
    "    return tf.keras.models.load_model(path)\n",
    "\n",
    "\n",
    "# save and restore only model weights\n",
    "def save_model2(model, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"model\")\n",
    "    model.save_weights(path)\n",
    "    return\n",
    "\n",
    "def restore_model2(model, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"model\")\n",
    "    model.load_weights(path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I modify `train3()` so that I can save and restore the model in two ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modification using the former way\n",
    "def train4(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period):\n",
    "    iterator = iter(data)\n",
    "\n",
    "    # restore the model\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        restore_iterator(iterator, initial_epoch, initial_step)\n",
    "        model = restore_model1(initial_epoch, initial_step)\n",
    "\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    logs = None\n",
    "    for epoch in range(initial_epoch, epochs):\n",
    "        if initial_step == 0:\n",
    "            iterator = iter(data)\n",
    "            model.reset_metrics()\n",
    "        \n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        for step in range(initial_step, steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            logs = train_fn(iterator)\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "\n",
    "            # save the model every \"step_period\" steps\n",
    "            if step_period != 0 and (step + 1) % step_period == 0:\n",
    "                save_iterator(iterator, epoch, step + 1)\n",
    "                save_model1(model, epoch, step + 1)\n",
    "\n",
    "        if initial_step != 0:\n",
    "            initial_step = 0\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "        # save the model every \"epochs_period\" epochs\n",
    "        if epoch_period != 0 and (epoch + 1) % epoch_period == 0:\n",
    "            save_iterator(iterator, epoch + 1, 0)\n",
    "            save_model1(model, epoch + 1, 0)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history\n",
    "\n",
    "\n",
    "# modification using the latter way\n",
    "def train5(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period):\n",
    "    iterator = iter(data)\n",
    "\n",
    "    # restore the model\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        restore_iterator(iterator, initial_epoch, initial_step)\n",
    "        restore_model2(model, initial_epoch, initial_step)\n",
    "\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    logs = None\n",
    "    for epoch in range(initial_epoch, epochs):\n",
    "        if initial_step == 0:\n",
    "            iterator = iter(data)\n",
    "            model.reset_metrics()\n",
    "        \n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        for step in range(initial_step, steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            logs = train_fn(iterator)\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "\n",
    "            # save the model every \"step_period\" steps\n",
    "            if step_period != 0 and (step + 1) % step_period == 0:\n",
    "                save_iterator(iterator, epoch, step + 1)\n",
    "                save_model2(model, epoch, step + 1)\n",
    "\n",
    "        if initial_step != 0:\n",
    "            initial_step = 0\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "        # save the model every \"epochs_period\" epochs\n",
    "        if epoch_period != 0 and (epoch + 1) % epoch_period == 0:\n",
    "            save_iterator(iterator, epoch + 1, 0)\n",
    "            save_model2(model, epoch + 1, 0)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model every 3 steps\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 1.8324 - accuracy: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 1.8124 - accuracy: 0.4900\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 1.8042 - accuracy: 0.5000\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5]}\n",
      "\n",
      "restart the training from the 3rd step of the second epoch\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7956 - accuracy: 0.5286\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 651us/step - loss: 1.8284 - accuracy: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 745us/step - loss: 1.8101 - accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 698us/step - loss: 1.8030 - accuracy: 0.4900\n",
      "{'loss': [1.7955976724624634, 1.8284294605255127, 1.810083270072937, 1.8030287027359009], 'accuracy': [0.5285714268684387, 0.49000000953674316, 0.5, 0.49000000953674316]}\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "print(\"save the model every 3 steps\")\n",
    "epochs = 5\n",
    "initial_epoch = 0\n",
    "initial_step = 0\n",
    "epoch_period = 0\n",
    "step_period = 3\n",
    "data, model = create_data_and_model()\n",
    "history = train4(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "# restore the model\n",
    "print(\"restart the training from the 3rd step of the second epoch\")\n",
    "epochs = 5\n",
    "initial_epoch = 1\n",
    "initial_step = 3\n",
    "epoch_period = 0\n",
    "step_period = 0\n",
    "data, model = create_data_and_model()\n",
    "history = train4(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model every 3 steps\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8324 - accuracy: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8124 - accuracy: 0.4900\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.8042 - accuracy: 0.5000\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5]}\n",
      "\n",
      "restart the training from the 3rd step of the second epoch\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7995 - accuracy: 0.5286\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 557us/step - loss: 1.8324 - accuracy: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 598us/step - loss: 1.8124 - accuracy: 0.4900\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 558us/step - loss: 1.8042 - accuracy: 0.5000\n",
      "{'loss': [1.7994781732559204, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5285714268684387, 0.49000000953674316, 0.49000000953674316, 0.5]}\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "print(\"save the model every 3 steps\")\n",
    "epochs = 5\n",
    "initial_epoch = 0\n",
    "initial_step = 0\n",
    "epoch_period = 0\n",
    "step_period = 3\n",
    "data, model = create_data_and_model()\n",
    "history = train5(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "# restore the model\n",
    "print(\"restart the training from the 3rd step of the second epoch\")\n",
    "epochs = 5\n",
    "initial_epoch = 1\n",
    "initial_step = 3\n",
    "epoch_period = 0\n",
    "step_period = 0\n",
    "data, model = create_data_and_model()\n",
    "history = train5(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the former is completely different, but I don't know the reason at the moment. \n",
    "\n",
    "On the other hand, the result of the latter after the third epoch looks the same.\n",
    "This is probably because the states of the metrics and the history are not saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Restore other information\n",
    "\n",
    "I modify `train5()` so that I can save and restore the metrics and the history.\n",
    "\n",
    "### metrics\n",
    "\n",
    "The metrics can be saved in the same as the iterator.\n",
    "\n",
    "But the metrics are created after the first `train_fn`. \n",
    "So I restore the metrics after the first `train_fn` to refer that objects.\n",
    "\n",
    "\n",
    "### history\n",
    "\n",
    "The history object (i.e. callback) cannot be saved.\n",
    "So I save and restore the attributes of the history object, `period` and `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# save metrics\n",
    "def save_metrics(model, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"metrics\")\n",
    "    ckpt = tf.train.Checkpoint()\n",
    "    ckpt.metrics = model.metrics\n",
    "    ckpt.save(path)\n",
    "    return\n",
    "\n",
    "\n",
    "# restore metrics\n",
    "def restore_metrics(model, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"metrics-1\")\n",
    "    ckpt = tf.train.Checkpoint()\n",
    "\n",
    "    # create initialized metrics\n",
    "    restored = []\n",
    "    for metric in model.metrics:\n",
    "        name = metric.name\n",
    "        if name == \"loss\":\n",
    "            name = \"Mean\"\n",
    "        name = \"\".join([w.capitalize() for w in  name.split(\"_\")])\n",
    "        restored.append(tf.keras.metrics.get(name))\n",
    "\n",
    "    # restore metrics\n",
    "    ckpt.metrics = restored\n",
    "    ckpt.restore(path)\n",
    "\n",
    "    # merge states and update logs\n",
    "    logs = {}\n",
    "    for m1, m2 in zip(model.metrics, restored):\n",
    "        m1.merge_state([m2])\n",
    "        logs[m1.name] = m1.result()\n",
    "    return logs\n",
    "\n",
    "\n",
    "# save a history\n",
    "def save_history(callbacks, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"history.pkl\")\n",
    "\n",
    "    # get the history object from callbacks\n",
    "    history = None\n",
    "    for callback in callbacks.callbacks:\n",
    "        if callback.__class__.__name__ == \"History\":\n",
    "            history = callback\n",
    "            break\n",
    "    joblib.dump({\"epoch\": history.epoch, \"history\": history.history}, path)\n",
    "    return\n",
    "\n",
    "\n",
    "# restore a history\n",
    "def restore_history(callbacks, epoch, step):\n",
    "    path = ckpt_path.format(epoch=epoch, step=step, name=\"history.pkl\")\n",
    "    restored = joblib.load(path)\n",
    "\n",
    "    for callback in callbacks.callbacks:\n",
    "        if callback.__class__.__name__ == \"History\":\n",
    "            callback.epoch = restored[\"epoch\"]\n",
    "            callback.history = restored[\"history\"]\n",
    "            break\n",
    "    return\n",
    "\n",
    "\n",
    "def train6(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period):\n",
    "    iterator = iter(data)\n",
    "\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        restore_iterator(iterator, initial_epoch, initial_step)\n",
    "        restore_model2(model, initial_epoch, initial_step)\n",
    "\n",
    "    steps = len(data)\n",
    "    callbacks = tf.keras.callbacks.CallbackList(add_history=True, add_progbar=True, model=model, epochs=epochs, steps=steps, verbose=True)\n",
    "\n",
    "    callbacks.on_train_begin()\n",
    "    train_fn = model.make_train_function()\n",
    "\n",
    "    # restore the hisotry\n",
    "    if initial_epoch != 0 or initial_step != 0:\n",
    "        restore_history(callbacks, initial_epoch, initial_step)\n",
    "\n",
    "    logs = None\n",
    "    for epoch in range(initial_epoch, epochs):\n",
    "        if initial_step == 0:\n",
    "            iterator = iter(data)\n",
    "            model.reset_metrics()\n",
    "        \n",
    "        callbacks.on_epoch_begin(epoch)\n",
    "\n",
    "        for step in range(initial_step, steps):\n",
    "            callbacks.on_train_batch_begin(step)\n",
    "            logs = train_fn(iterator)\n",
    "\n",
    "            # restore the metrics and update the logs\n",
    "            if initial_step != 0 and step == initial_step:\n",
    "                logs = restore_metrics(model, initial_epoch, initial_step)\n",
    "\n",
    "            callbacks.on_train_batch_end(step + 1, logs)\n",
    "            \n",
    "            # save the metrics and the history every \"epochs_period\" epochs\n",
    "            if step_period != 0 and (step + 1) % step_period == 0:\n",
    "                save_iterator(iterator, epoch, step + 1)\n",
    "                save_model2(model, epoch, step + 1)\n",
    "                save_metrics(model, epoch, step + 1)\n",
    "                save_history(callbacks, epoch, step + 1)\n",
    "\n",
    "        if initial_step != 0:\n",
    "            initial_step = 0\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs)\n",
    "\n",
    "        # save the metrics and the history every \"epochs_period\" epochs\n",
    "        if epoch_period != 0 and (epoch + 1) % epoch_period == 0:\n",
    "            save_iterator(iterator, epoch + 1, 0)\n",
    "            save_model2(model, epoch + 1, 0)\n",
    "            save_metrics(model, epoch + 1, 0)\n",
    "            save_history(callbacks, epoch + 1, 0)\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "    return model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the metrics and the history every 3 steps\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 2.1481 - accuracy: 0.5100\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.9838 - accuracy: 0.4900\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.8324 - accuracy: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.8124 - accuracy: 0.4900\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.8042 - accuracy: 0.5000\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5]}\n",
      "\n",
      "restart the training from the 3rd step of the second epoch\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.8324 - accuracy: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 598us/step - loss: 1.8124 - accuracy: 0.4900\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 697us/step - loss: 1.8042 - accuracy: 0.5000\n",
      "{'loss': [2.1480836868286133, 1.9837868213653564, 1.8324090242385864, 1.812350869178772, 1.8041961193084717], 'accuracy': [0.5099999904632568, 0.49000000953674316, 0.49000000953674316, 0.49000000953674316, 0.5]}\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "print(\"save the metrics and the history every 3 steps\")\n",
    "epochs = 5\n",
    "initial_epoch = 0\n",
    "initial_step = 0\n",
    "epoch_period = 2\n",
    "step_period = 3\n",
    "data, model = create_data_and_model()\n",
    "history = train6(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "print(history.history)\n",
    "\n",
    "print()\n",
    "\n",
    "# restore the model\n",
    "print(\"restart the training from the 3rd step of the second epoch\")\n",
    "epochs = 5\n",
    "initial_epoch = 2\n",
    "initial_step = 3\n",
    "epoch_period = 0\n",
    "step_period = 0\n",
    "data, model = create_data_and_model()\n",
    "history = train6(data, model, epochs, initial_epoch, initial_step, epoch_period, step_period)\n",
    "print(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77380b671049c866ddb2cbea35f435cceddb611c25b08154848521dfc0769a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
